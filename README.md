# Positive-dialog-summarization-using-LLM-s

# Overview : Engineered fine-tuning of a Large Language Model (LLM) to generate human like summaries with a focus on reducing toxicity
# • Fine-tuned FLAN-T5 on DialogSum dataset using LoRA technique and achieved 12.34% improvement in ROUGE-L-SUM score

# • Implemented RLHF technique along with PPO algorithm to further fine-tune the model to mitigate the model toxicity in the output

# •  Achived a 44% reduction in the model toxicity by utilizing META's RoBERT-based hate spech classifier as a reward model
